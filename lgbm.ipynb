{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "credit_lgbm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBoVcChn9OWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "ecfd3419-4da9-42a7-d24a-e55b7861a62a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ1ZS9g5cZm2",
        "colab_type": "text"
      },
      "source": [
        "As I realized from previous experience to get better performance, we need use source dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDUbZx7e9fW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_ds = pd.read_csv('/content/drive/My Drive/credit/trainDS.csv')\n",
        "test_ds = pd.read_csv('/content/drive/My Drive/credit/testDS.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Lk65kaO9lM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, recall_score\n",
        "import lightgbm as lgb\n",
        "import gc\n",
        "import numpy as np\n",
        "\n",
        "def model(features, test_features, n_folds = 5):\n",
        " \n",
        "    labels = train_ds['target']\n",
        "    prediction = train_ds.copy()\n",
        "    \n",
        "    features = train_ds.drop(columns = 'target')\n",
        "\n",
        "    features.feature4 = features.feature4.replace(' ', -999).astype(int)\n",
        "    features.feature9 = features.feature9.replace(' ', -1).astype(int)\n",
        "\n",
        "    test_features.feature4 = test_features.feature4.replace(' ', -999).astype(int)\n",
        "    test_features.feature9 = test_features.feature9.replace(' ', -1).astype(int)\n",
        "        \n",
        "    print('Training Data Shape: ', features.shape)\n",
        "    print('Testing Data Shape: ', test_features.shape)\n",
        "\n",
        "    feature_names = list(features.columns)\n",
        "\n",
        "    features = np.array(features)\n",
        "    test_features = np.array(test_features)\n",
        "\n",
        "    k_fold = StratifiedKFold(n_splits = 5, shuffle = True)\n",
        "\n",
        "    test_predictions = np.zeros(test_features.shape[0])\n",
        "    out_of_fold = np.zeros(features.shape[0])\n",
        "    \n",
        "    for train_indices, valid_indices in k_fold.split(features, labels):\n",
        "        \n",
        "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
        "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
        "\n",
        "        model = lgb.LGBMClassifier(n_estimators=500, objective = 'binary', \n",
        "                                   learning_rate = 0.05, \n",
        "                                   reg_alpha = 0.3,  reg_lambda = 0.1,\n",
        "                                   subsample = 1.0, n_jobs = -1)\n",
        "        model.fit(train_features, train_labels, \n",
        "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
        "                  eval_names = ['valid', 'train'],\n",
        "                  early_stopping_rounds = 100, \n",
        "                  verbose = 100)\n",
        "        \n",
        "        best_iteration = model.best_iteration_\n",
        "        \n",
        "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
        "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
        "        \n",
        "        gc.enable()\n",
        "        del model, train_features, valid_features\n",
        "        gc.collect()\n",
        "        \n",
        "    test_prediction = pd.DataFrame({'preds_1': test_predictions})\n",
        "    prediction['preds_1'] = out_of_fold\n",
        "\n",
        "    f1 = f1_score(labels, (out_of_fold>0.5))\n",
        "    recall = recall_score(labels, (out_of_fold>0.5))\n",
        "    \n",
        "    metrics = {'F1 Score': [f1], 'Recall': [recall]} \n",
        "    \n",
        "    return test_prediction, prediction, metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjIbejo29sNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "e9812e72-fb52-4319-a33f-1b3d2ed2b906"
      },
      "source": [
        "test_prediction, prediction, metrics = model(train_ds, test_ds)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data Shape:  (73276, 10)\n",
            "Testing Data Shape:  (31405, 10)\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttrain's binary_logloss: 0.164074\tvalid's binary_logloss: 0.176633\n",
            "Early stopping, best iteration is:\n",
            "[95]\ttrain's binary_logloss: 0.164664\tvalid's binary_logloss: 0.176592\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttrain's binary_logloss: 0.162716\tvalid's binary_logloss: 0.181773\n",
            "Early stopping, best iteration is:\n",
            "[91]\ttrain's binary_logloss: 0.163929\tvalid's binary_logloss: 0.181746\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttrain's binary_logloss: 0.163989\tvalid's binary_logloss: 0.176874\n",
            "[200]\ttrain's binary_logloss: 0.154198\tvalid's binary_logloss: 0.177232\n",
            "Early stopping, best iteration is:\n",
            "[114]\ttrain's binary_logloss: 0.162383\tvalid's binary_logloss: 0.176825\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttrain's binary_logloss: 0.164414\tvalid's binary_logloss: 0.176011\n",
            "[200]\ttrain's binary_logloss: 0.154654\tvalid's binary_logloss: 0.176623\n",
            "Early stopping, best iteration is:\n",
            "[105]\ttrain's binary_logloss: 0.163849\tvalid's binary_logloss: 0.175945\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttrain's binary_logloss: 0.163244\tvalid's binary_logloss: 0.179047\n",
            "[200]\ttrain's binary_logloss: 0.152881\tvalid's binary_logloss: 0.18002\n",
            "Early stopping, best iteration is:\n",
            "[100]\ttrain's binary_logloss: 0.163244\tvalid's binary_logloss: 0.179047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amzsPgKR95qh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88c9055a-177f-458c-9114-263f19a44a49"
      },
      "source": [
        "metrics"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'F1 Score': [0.29344465058750774], 'Recall': [0.19391091131998364]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY9cFzdOdtyY",
        "colab_type": "text"
      },
      "source": [
        "Little bit better then Random Forest, so we will use probabilities as **meta-feature** for final model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw9hagU7-Eg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction.to_csv('/content/drive/My Drive/credit/train_predictions_lgbm.csv', index_label='idx')\n",
        "test_prediction.to_csv('/content/drive/My Drive/credit/test_predictions_lgbm.csv', index_label='idx')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}